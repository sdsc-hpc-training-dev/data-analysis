{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript Word Counts\n",
    "By: Jonathan Lo<br>\n",
    "Date: 10/3/23<br>\n",
    "Goal is to retrieve all transcripts and find the words with the highest counts. This is after removing unnecessary words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "\n",
    "# Stop Words\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ignored words\n",
    "with open(\"ignore.txt\", 'r') as fh:\n",
    "    LOCAL_STOP_WORDS = fh.readlines()[0]\n",
    "    LOCAL_STOP_WORDS = LOCAL_STOP_WORDS.split(',')\n",
    "\n",
    "try:\n",
    "    NLTK_STOP_WORDS = set(stopwords.words('english'))\n",
    "except LookupError as e:\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    NLTK_STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "NLTK_STOP_WORDS = [word.replace(\"'\", '') for word in NLTK_STOP_WORDS]\n",
    "ENGLISH_STOP_WORDS = [word.replace(\"'\", '') for word in ENGLISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all transcripts\n",
    "corpus = []\n",
    "for iv_dir in glob(\"../../*/*.vtt\"):\n",
    "    try:\n",
    "        with open(os.path.join(iv_dir), 'r') as file:\n",
    "            corpus.append(file.read())\n",
    "    except Exception as e:\n",
    "        print(f\".vtt file not found in dir {iv_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean timestamsp and meta information\n",
    "master_transcript = \"\"\n",
    "for transcript in corpus:\n",
    "    clean_transcript = re.sub(r'\\d{2}:\\d{2}:\\d{2}.\\d{3} --> \\d{2}:\\d{2}:\\d{2}.\\d{3}\\n', '', transcript)\n",
    "    clean_transcript = re.sub(r'\\n\\d+\\n', '\\n', clean_transcript)\n",
    "    clean_transcript = clean_transcript\\\n",
    "                        .replace('\\ufeffWEBVTT', '')\\\n",
    "                        .replace('\\n', '')\\\n",
    "                        .replace('<v ->', '')\\\n",
    "                        .replace('</v>', '')\\\n",
    "                        .replace(\"'\", '')\\\n",
    "                        .replace(',', ' ')\\\n",
    "                        .replace('.', ' ')\\\n",
    "                        .lower()\n",
    "    master_transcript += \" \" + clean_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean ignored words from master transcript\n",
    "filtered_words = list(filter(lambda w: not w in ENGLISH_STOP_WORDS, master_transcript.split()))\n",
    "filtered_words = list(filter(lambda w: not w in NLTK_STOP_WORDS, filtered_words))\n",
    "filtered_words = list(filter(lambda w: not w in LOCAL_STOP_WORDS, filtered_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>code</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expanse</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>running</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>machine</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>hardware</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>version</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>model</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>information</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Count\n",
       "0          data    606\n",
       "1          file    546\n",
       "2          code    529\n",
       "3       expanse    473\n",
       "4       running    444\n",
       "..          ...    ...\n",
       "70      machine     92\n",
       "71     hardware     92\n",
       "72      version     91\n",
       "73        model     90\n",
       "74  information     86\n",
       "\n",
       "[75 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather top word counts\n",
    "word_counts = Counter(filtered_words)\n",
    "df = pd.DataFrame(word_counts.most_common(75), columns=['Word', 'Count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "df.to_csv(\"transcript_word_counts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
